{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joby John\n",
    "## Week 10/11 Assignment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "For this project, we will use the Reuters Corpus data set that comes with NLTk. Dataset contains 10,788 financial news articles with around 1.3 million words. The documents have been classified into 90 business topics.\n",
    "For instance,\n",
    "    earning reports are flagged as 'earn'; \n",
    "    commodity price reports are labeled as commodity label ('crude' or 'palm-oil');\n",
    "    economic indicators are labeled as type ('cpi', 'gnp')\n",
    "\n",
    "We will split the dataset into training and test data. We will train the  model with the training dataset and  predict the class of documents in the test dataset. For news articles with multiple labels, we used label listed first to train and test. We will train the models using Naive Bayes and SVM classifiers and compare the accuracy of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import codecs\n",
    "import sys\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.colors as colors\n",
    "plot.rcParams['figure.figsize'] = (21, 14)\n",
    "from scipy.stats import rankdata\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import reuters\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will normalize text and remove non-words and stop words. We will also stem words using the Porter stemmer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " docs = [(reuters.raw(fileid), category)\n",
    "    for category in reuters.categories()\n",
    "    for fileid in reuters.fileids(category)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will tokenize the text, remove any non words and remove any words that are less than 3 characters long.  \n",
    "\n",
    "and then procceds to stem the word down to its \"root\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "StopWords = stopwords.words()\n",
    " \n",
    "def tokenize(text):\n",
    "    min_length = 3\n",
    "    words = map(lambda word: word.lower(), word_tokenize(text));\n",
    "    words = [word for word in words\n",
    "                  if word not in StopWords]\n",
    "    tokens =(list(map(lambda token: PorterStemmer().stem(token),\n",
    "                  words)));\n",
    "    p = re.compile('[a-zA-Z]+');\n",
    "    filtered_tokens = list(filter(lambda token:\n",
    "         p.match(token) and len(token)>=min_length,\n",
    "         tokens));\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a new document list after passing each document through the tokenizing function.\n",
    "documents2 = []\n",
    "for doc in docs:\n",
    "    documents2.append((tokenize(doc[0]), doc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extractor\n",
    "\n",
    "We will select the 2,000 most-common words and build a feature extractor.\n",
    "For document topic identification, we can define a feature for each word, indicating whether the document contains that word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_words = [word.lower() for word in reuters.words() if word.isalpha()]\n",
    "t_words = [w for w in t_words if w not in StopWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asian',\n",
       " 'exporters',\n",
       " 'fear',\n",
       " 'damage',\n",
       " 'japan',\n",
       " 'rift',\n",
       " 'mounting',\n",
       " 'trade',\n",
       " 'friction']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(t_words)[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2,000 most common words\n",
    "all_words = nltk.FreqDist(t_words)\n",
    "word_features = all_words.most_common(2000)\n",
    "\n",
    "## get just the words, no counts\n",
    "word_features = [w for (w,v) in word_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asian': 65,\n",
       " 'exporters': 255,\n",
       " 'fear': 51,\n",
       " 'damage': 143,\n",
       " 'japan': 1890,\n",
       " 'rift': 3,\n",
       " 'mounting': 22,\n",
       " 'trade': 3098,\n",
       " 'friction': 29,\n",
       " 'raised': 351}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "\n",
    "dict(list(all_words.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['said', 'mln', 'vs', 'dlrs', 'pct', 'lt', 'cts', 'year', 'net']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update feature extractor with new features\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating the feature set and trainign and test sets.\n",
    "featuresets = [(document_features(d), c) for (d, c) in documents2]\n",
    "train_set, test_set = featuresets[1000:], featuresets[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "We see the the accuracy of the test set is about 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 80.7%.\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is {}%.\".format(nltk.classify.accuracy(classifier, test_set)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table belwo dispalys the most informative featues. As expected, occurance of a specific commodity name in a document is a strong predictor of commodity category. The two most informative word features are 'palm' and 'sorghum.' and  'Indonesia', the largest world producer palm oil. Also, 'saudi' and 'arabia' are most informative features for the 'propane' category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    palm = True           palm-o : earn   =   2611.1 : 1.0\n",
      "                 sorghum = True           sorghu : earn   =   2454.5 : 1.0\n",
      "               economist = True             rand : earn   =   2312.9 : 1.0\n",
      "               indonesia = True           copra- : earn   =   2312.9 : 1.0\n",
      "              indonesian = True           copra- : earn   =   1652.1 : 1.0\n",
      "                    crop = True           copra- : earn   =   1652.1 : 1.0\n",
      "                  tariff = True              dfl : earn   =   1652.1 : 1.0\n",
      "                  arabia = True           propan : earn   =   1321.7 : 1.0\n",
      "                   cargo = True           propan : earn   =   1321.7 : 1.0\n",
      "                   saudi = True           propan : earn   =   1321.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Support Vector Machine(SVM) Classifier\n",
    "\n",
    "We will use the SVM classifier in the Scikit-Learn machine learning package  \n",
    "We will use TF-IDF to normalize the word feature set and classify documents using SVM classifier. \n",
    "\n",
    "Reference \n",
    "https://www.quantstart.com/articles/Supervised-Learning-for-Document-Classification-with-Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for id in range(len(nltk.corpus.reuters.fileids())):\n",
    "    file = nltk.corpus.reuters.raw(fileids=list(nltk.corpus.reuters.fileids())[id])\n",
    "    corpus.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for id in range(len(nltk.corpus.reuters.fileids())):\n",
    "    cat = nltk.corpus.reuters.categories(fileids=list(nltk.corpus.reuters.fileids())[id])\n",
    "    topics.append(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_topics(topics):\n",
    "    categories = []\n",
    "    for i in range(len(topics)):\n",
    "        if topics[i][0] in nltk.corpus.reuters.categories():           \n",
    "            categories.append(topics[i][0])\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = filter_topics(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and Training sets\n",
    "\n",
    "We will use 80% for training the classifier and  20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000000.0, gamma='auto')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(C=1000000.0, gamma='auto', kernel='rbf')\n",
    "svm.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8934198331788693"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = svm.predict(X_test)\n",
    "\n",
    "score = svm.score(X_test, y_test)\n",
    "score\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Result Discussion\n",
    "We trained SVM and Naive classifer on training set and tested the accuracy of the models on the test set. \n",
    "Based on the accuracy we calculated on the test set above, we see that \n",
    "SVM classifier has a higher overall classification accuracy(90%) compared to Naive Bayes (84%).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
